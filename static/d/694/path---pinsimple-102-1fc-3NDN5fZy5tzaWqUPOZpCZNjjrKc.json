{"data":{"markdownRemark":{"html":"<h1>Shareable Caustics</h1>\n<p>In the desire to understand the extended reality ecosystem for the ideal open, interoperable and cross-platform file type for 3D interactables, which is fundamental to unlocking the next generation of creativity we analyze modern viewing methods.  </p>\n<div style=\"background:#D4D3D3; padding: 10px; margin: 40px; box-shadow: 0 6px 8px 0 rgba(0,0,0,0.2)\"> Shareable Caustics is a class of interactive methods for objects in mixed reality. It is casual to share files like videos, audio and text over the internet. However , there is no standard for sharing 3D objects,audio or text files combined with specific interaction.</div>\n<p>Mixed reality product marketplace means a lot of sharing capabilities will be explored. CGI (<strong>computer-generated imagery</strong>) sharing will enable ergonomically sustainable usage for the affordance for personas (users). A way to enable zero-sum game is an interaction in which some combinations of actions provide a net gain or loss to the two of them.</p>\n<h2>Digital Dualism</h2>\n<p>Nathan Jurgenson is a sociologist and social media theorist at Snapchat.\nThis perspective rejects the digital dualist position that the digital and physical are separate spheres and instead promotes the idea that atoms and bits enmesh to create our augmented reality. \nAs Thiel would say, we've seen \"innovation in the world of bits, but not in the world of atoms.\"\nNeil Gershenfeld, director of MIT's Center for Bits and Atoms</p>\n<h3><p style=\"color: darkgrey\"> Could Grover’s quantum algorithm help in searching an actual database?</p></h3>\n<h3>Shopify</h3>\n<iframe src='https://gfycat.com/ifr/PlasticSophisticatedGoa' frameborder='0' scrolling='no' allowfullscreen width='640' height='404'></iframe><p> <a href=\"https://gfycat.com/plasticsophisticatedgoa-shopify-webvr\"></a></p>\n<p>How do you send a digital vinyl record to your friend and allow them to play it remotely on ther device, moreover , what do we even call that interaction file we just sent? What do we call catching Pokemons when they are something else, what does catching mean? These are the motivations for going through a list of shareable methods for interaction design</p>\n<hr>\n<h1>Microformats</h1>\n<p>The question above can technically be posed as : \n\"What is a review or event? What are the specific fields in the data structure?\"\nMicroformat lets both user and machine understand and answer these questions equivocally. A  web of data sources, services for exploring and manipulating data, and ways that users can connect them together. Aggregation Network \nModel is a microformat for publishing 3D objects </p>\n<pre><code class=\"language-javascript\"> &#x3C;a class=\"h-card\" href=\"http://medium.com\">Tim Coates&#x3C;/a>\n</code></pre>\n<h1>Superformats</h1>\n<p>The important competing 3d models are  glTF2.0 and USDZ .</p>\n<blockquote>\n<h2>USDZ</h2>\n<p>Apple launched this new open file format that enables several new experiences. These were designed to exchange source art assets in the content pipeline of a film studio. They are fantastic for that use case, but they were never designed for the needs of real-time client-side rendering applications like Apple is promoting it for.\nSafari on iOS 12 supports viewing 3D models and allows you to see them in Augmented Reality (AR). Supported assets use the Universal Scene Description format, or USDZ, developed by Pixar. </p>\n<pre><code>&#x3C;a rel=\"ar\" href=\"model.usdz\">\n</code></pre>\n</blockquote>\n<pre><code>&#x3C;img src=\"model-preview.jpg\">\n</code></pre>\n</a>\n```\n> ## gLTF 2.0\nglTF™ (GL Transmission Format) is a royalty-free specification for the efficient transmission and loading of 3D scenes and models by applications.\nglTf is the current best practice for runtime delivery formats.\nPBR-based materials, glTF 2.0 is a stable base for the future and will support practical runtime implementations for many graphics APIs. \n<p>Features include: Graphics API neutral,  Physically Based Rendering (PBR) material definitions <em>(Material information stored in textures)</em>, Deployment as single file <em>(Binary glTF )</em>, Morph Targets <em>(enhanced animation system)</em></p>\n<blockquote>\n<h2>Windows Mixed Reality</h2>\n</blockquote>\n<blockquote>\n<h2>SFA</h2>\n</blockquote>\n<p>Sceneform assets are assets that are encoded insides Google's Sceneforms API. They store information about the model. They work inside android studio for ARCore.  For runtime, you can use the SFB, which is the binary for SFA.</p>\n<blockquote>\n<h2>Point-Clouds</h2>\n</blockquote>\n<p>A point cloud is a set of data points in some coordinate system <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi mathvariant=\"double-struck\">R</mi><mn>3</mn></msup></mrow><annotation encoding=\"application/x-tex\">\\mathbb R^3</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span></span></span></span> .</p>\n<p>The PLY file format defines vertices and (polygon) faces. This means the intersection(s) between a plane and the polygons defined in a PLY file are polylines (or polygons).</p>\n<blockquote>\n<h3>In this series we ask the question, what shall we call the meriad of 3D shareable assets in digital realities, considering the interaction they inhibit ?</h3>\n</blockquote>\n<h4>The AR Cloud</h4>\n<p>There are three major components of the AR Cloud:</p>\n<li >A scalable and shareable machine readable representation of the world aligned with real world coordinates . It could for instance be implemented with point-clouds.</li>\n<li> The ability to instantly localize (align the world’s soft-copy with the world itself) from anywhere and on multi devices</li>\n<li> The ability to place virtual content in the world’s soft-copy and interact with it in realtime, on-device and remotely\n</li>\n<hr>\n<h1>Three classes of Caustic Shareables : </h1>\n<blockquote>\n<h3>Hard Caustic  |  Soft Caustics |   Augmented Caustics</h3>\n</blockquote>\n<h2>1. Hard Caustic(Haustics)</h2>\n<p>These are hard surfaces in the physical world that can recieve signals from the real world to the digital. Interaction in this case is designed as a Natural User Interface. So a keyboard falls under this class, here is the most general and ubitiquous model. In a more general sense we have a detached surface that responses to gestures. One example of this is <a href=\"https://www.hypersurfaces.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">hypersurfaces</a>, this includes a series of modular UI that is embedded as IoT and/or sensors.  Ofcourse, we consider non-locality <em>( spooky action-at-a-distance)</em> as a subject falling under this class.</p>\n<iframe title=\"vimeo-player\" src=\"https://player.vimeo.com/video/295596170\" width=\"640\" height=\"268\" frameborder=\"0\" allowfullscreen></iframe>\nThis method is purely based on haptics as an input.\n<h2>2. Soft Caustics (Saustics)</h2>\n<p>This is hardware designed to help interact within a software.In the WAVE VR application these soft caustics are known as waves. Input is usually limited to the electromagnetic spectrum radiation,hardware(joysticks,knucles .etc).</p>\n<h4>Soli</h4>\n<iframe width=\"640\" height=\"268\" src=\"https://www.youtube.com/embed/0QNiZfSsPc0\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\nSoli is a Google project using  RADAR as a base technology for sensing microgestures. Its chip transmits a millimetre-wave radar electromagnetic waves of wavelength  1mm $\\to$ 10mm which are longer than infrared rays and x-rays but, smaller compared to radiowaves and microwaves.\n<p>Hardware that can interact with software as a shareable.</p>\n<h4>Leap Motion</h4>\n<p>These track infrared light with a wavelength of 850 nanometers, which is outside the visible light spectrum. The data takes the form of a grayscale stereo image of the near-infrared light spectrum, separated into the left and right cameras. Typically, the only objects you’ll see are those directly illuminated by the Leap Motion Controller’s LEDs.  Algorithms from this sensor are not depth-mapping but computer vision oriented.</p>\n<h2>3. Augmented Caustics (Augstics)</h2>\n<p>Veemo controlling a drone with an AR mobile app.</p>\n<h2>Shannon</h2>\n<h3>Information Entropy</h3>\n<p>In 1948, Claude Shannon, a young engineer and mathematician working at the Bell Telephone Laboratories, published \"A Mathematical Theory of Communication,\" a seminal paper that marked the birth of information theory. In that paper, Shannon defined what <strong>\"information\"</strong> meant for communication engineers and proposed a precise way to quantify it-in his theory, the fundamental unit of information is the bit.</p>\n<div style=\"background:#D4D3D3; padding: 10px; margin: 40px; box-shadow: 0 6px 8px 0 rgba(0,0,0,0.2)\"> \nHe also showed how data could be \"compressed\" before transmission and how virtually error-free communication could be achieved. The concepts Shannon developed in his paper are at the heart of today's digital information technology. CDs, DVDs, cell phones, fax machines, modems, computer networks, hard drives, memory chips, encryption schemes, MP3 music, optical communication, high-definition television-all these things embody many of Shannon's ideas.\nWhat he showed is you can communicate reliably even though the communication medium is unreliable; that's what digital means.\n</div>\n<p>Shannon’s limit is often referred to as channel capacity.32</p>\n<p>The one that's most interesting for me is he proved the first threshold theorem. What that means is I could send my voice to you today as a wave, or I could send it to you as a symbol. What he showed is if I send it to you as a symbol, for a linear increase in the resource used to represent the symbol, there is an exponential reduction in the error of you getting the symbol correctly as long as the noise is below a threshold. If the noise is above the threshold, you're doomed. If it's below a threshold, a linear increase in the symbol gives you an exponential reduction in error.</p>\n<h3>Entropy</h3>\n<div style=\"background:#D4D3D3; display:flex; padding: 10px; margin: 40px; box-shadow: 0 6px 8px 0 rgba(0,0,0,0.2)\"> \n<img src=\"https://i.redd.it/7ek2amf1s0rz.png\" alt=\"billinfo\" style=\"width:50%; height: 50%\">\n<p style=\"display:inline; margin: 12px; font-size:18px; color: blue\"> Bill Gates showing information equaivalence of a log of paper sheets&#xA0;\n&quot;This CD-ROM can hold more information than all the paper that&apos;s here below me&quot;\n- Bill Gates,1994. \n<br>\n<br>\nShot in 1994 for  a National Geographic story called the Information Revolution. For one of the pictures to illustrate the power of digital storage and came up with the idea of showing how much information can be stored on a CD. At the time, it was 330,000 sheets of single spaced 8x10 single pieces of paper. </p>\n</div>\n<p>Thus the human body might be the most unreliable device but according to Von Neuman that doesnt stop it from being an excellent commucation .</p>","frontmatter":{"path":"/pinsimple","title":"Caustic Shareables","date":"2018-12-23"}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/pinsimple/"}}